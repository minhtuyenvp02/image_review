{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxy2-jooDdfW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install torchtext\n",
        "!pip install matplotlib\n",
        "!pip install torchvision\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install timm\n",
        "!pip install scikit_learn\n",
        "!pip install pandas\n",
        "!pip install opencv_contrib_python\n",
        "!pip install opencv_python_headless\n",
        "! pip install torchsummary\n",
        "! pip install einops\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "H-661kLOD6WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import albumentations as A\n",
        "\n",
        "import timm\n",
        "from pytorch_lightning.utilities.model_summary import ModelSummary, summarize\n",
        "from pytorch_lightning.tuner.tuning import Tuner\n",
        "from einops.layers.torch import Rearrange\n",
        "from torchmetrics import ConfusionMatrix\n",
        "from scipy.ndimage import gaussian_filter1d, convolve1d\n",
        "from scipy.signal.windows import triang\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, RichProgressBar\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from collections import OrderedDict\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import shutil\n",
        "\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import display\n"
      ],
      "metadata": {
        "id": "HBS5JTpaD_mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class QualityDataset(Dataset):\n",
        "\n",
        "    def __init__(self, parent_dir, annotated_path, is_train=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.parent_dir = parent_dir\n",
        "        self.annotated_file = pd.read_csv(annotated_path)\n",
        "\n",
        "        if is_train:\n",
        "            self.transforms = A.Compose([\n",
        "                A.Resize(384, 512),\n",
        "                # A.HorizontalFlip(p=0.3),\n",
        "                A.Normalize(\n",
        "                    mean=(0.5, 0.5, 0.5),\n",
        "                    std=(0.5, 0.5, 0.5),\n",
        "                ),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "        else:\n",
        "            self.transforms = A.Compose([\n",
        "                A.Resize(384, 512),\n",
        "                A.Normalize(\n",
        "                    mean=(0.5, 0.5, 0.5),\n",
        "                    std=(0.5, 0.5, 0.5),\n",
        "                ),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotated_file)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        info = self.annotated_file.iloc[index]\n",
        "\n",
        "        image_path = os.path.join(\n",
        "            self.parent_dir, info[\"image_name\"]\n",
        "        )\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = self.transforms(image=image)[\"image\"]\n",
        "\n",
        "        rating = info[\"MOS\"]\n",
        "\n",
        "        rating = torch.tensor(rating, dtype=torch.float32)\n",
        "\n",
        "        return image, rating\n",
        "\n",
        "class QualityDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, parent_dir, train_csv, val_csv, batch_size=128):\n",
        "        super().__init__()\n",
        "\n",
        "        self.parent_dir = parent_dir\n",
        "        self.train_csv = train_csv\n",
        "        self.val_csv = val_csv\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def setup(self, stage):\n",
        "        self.train_data = QualityDataset(self.parent_dir, self.train_csv, is_train=True)\n",
        "        self.val_data = QualityDataset(self.parent_dir, self.val_csv)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True, num_workers=12)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_data, batch_size=self.batch_size, num_workers=12)\n",
        "\n",
        "# class QualityDataset(Dataset):\n",
        "\n",
        "#     def __init__(self, parent_dir, annotated_path, is_train=False):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.parent_dir = parent_dir\n",
        "#         self.annotated_file = pd.read_csv(annotated_path)\n",
        "\n",
        "#         if is_train:\n",
        "#             self.transforms = A.Compose([\n",
        "#                 A.Resize(224, 224),\n",
        "#                 A.HorizontalFlip(p=0.5),\n",
        "#                 A.Normalize(\n",
        "#                     mean=(0.485, 0.456, 0.406),\n",
        "#                     std=(0.229, 0.224, 0.225),\n",
        "#                 ),\n",
        "#                 ToTensorV2()\n",
        "#             ])\n",
        "#         else:\n",
        "#             self.transforms = A.Compose([\n",
        "#                 A.Resize(224, 224),\n",
        "#                 A.Normalize(\n",
        "#                     mean=(0.485, 0.456, 0.406),\n",
        "#                     std=(0.229, 0.224, 0.225),\n",
        "#                 ),\n",
        "#                 ToTensorV2()\n",
        "#             ])\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.annotated_file)\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         info = self.annotated_file.iloc[index]\n",
        "\n",
        "#         image_path = os.path.join(\n",
        "#             self.parent_dir, info[\"image_name\"]\n",
        "#         )\n",
        "#         image = cv2.imread(image_path)\n",
        "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#         image = self.transforms(image=image)[\"image\"]\n",
        "\n",
        "#         rating = info[\"cate\"]\n",
        "\n",
        "#         rating = torch.tensor(rating, dtype=torch.long)\n",
        "\n",
        "#         return image, rating\n",
        "\n",
        "# class QualityDataModule(pl.LightningDataModule):\n",
        "\n",
        "#     def __init__(self, parent_dir, train_csv, val_csv, batch_size=128):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.parent_dir = parent_dir\n",
        "#         self.train_csv = train_csv\n",
        "#         self.val_csv = val_csv\n",
        "#         self.batch_size = batch_size\n",
        "\n",
        "#     def setup(self, stage):\n",
        "#         self.train_data = QualityDataset(self.parent_dir, self.train_csv, is_train=True)\n",
        "#         self.val_data = QualityDataset(self.parent_dir, self.val_csv)\n",
        "\n",
        "#     def train_dataloader(self):\n",
        "#         return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True, num_workers=12)\n",
        "\n",
        "#     def val_dataloader(self):\n",
        "#         return DataLoader(self.val_data, batch_size=self.batch_size, num_workers=12)\n",
        "\n",
        "class ReviewDataset(Dataset):\n",
        "\n",
        "    def __init__(self, annotated_path, is_train=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.annotated_file = pd.read_csv(annotated_path)\n",
        "\n",
        "        if is_train:\n",
        "            self.transforms = A.Compose([\n",
        "                A.Resize(224, 224),\n",
        "#                 A.Flip(p=0.5),\n",
        "                A.Normalize(\n",
        "                    mean=[0.5, 0.5, 0.5],\n",
        "                    std=[0.5, 0.5, 0.5],\n",
        "                ),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "        else:\n",
        "            self.transforms = A.Compose([\n",
        "                A.Resize(224, 224),\n",
        "                A.Normalize(\n",
        "                    mean=[0.5, 0.5, 0.5],\n",
        "                    std=[0.5, 0.5, 0.5],\n",
        "                ),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotated_file)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        info = self.annotated_file.iloc[index]\n",
        "\n",
        "        image_path = info[\"Image\"]\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = self.transforms(image=image)[\"image\"]\n",
        "\n",
        "        rating = info[\"Rating\"]\n",
        "\n",
        "        rating = torch.tensor(rating, dtype=torch.float32)\n",
        "\n",
        "        return image, rating\n",
        "\n",
        "class ReviewDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, train_csv, val_csv, batch_size=128):\n",
        "        super().__init__()\n",
        "\n",
        "        self.train_csv = train_csv\n",
        "        self.val_csv = val_csv\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def setup(self, stage):\n",
        "        self.train_data = ReviewDataset(self.train_csv, is_train=True)\n",
        "        self.val_data = ReviewDataset(self.val_csv)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True, num_workers=12)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_data, batch_size=self.batch_size, num_workers=12)\n"
      ],
      "metadata": {
        "id": "CCRgRXyKDlse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LOSS"
      ],
      "metadata": {
        "id": "mlMxtI2UFR3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RFCLoss(nn.Module):\n",
        "    def __init__(self, alpha=10, min_delta=0.47, loss=nn.L1Loss(reduction = 'none')):\n",
        "        super().__init__()\n",
        "\n",
        "        self.loss = loss\n",
        "        self.alpha = alpha\n",
        "        self.min_delta = min_delta\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        mae_loss = torch.abs(y_pred - y_true)\n",
        "        weights = 1/(1 + torch.exp(self.alpha * (self.min_delta - mae_loss)))\n",
        "        loss = weights * self.loss(y_pred, y_true)\n",
        "\n",
        "        return torch.mean(loss).cuda()"
      ],
      "metadata": {
        "id": "oh_MST8-FPL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DPD BLOCK"
      ],
      "metadata": {
        "id": "ch6eSFInE9ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timm.models.layers import DropPath\n",
        "class DPDBlockV1(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        expand_channels,\n",
        "        freeze_channels,\n",
        "        is_downsize=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.expand_channels = self._make_divisible(expand_channels, in_channels)\n",
        "        self.freeze_channels = freeze_channels\n",
        "        self.is_downsize = is_downsize\n",
        "\n",
        "        self.depthwise_expand = nn.Sequential(\n",
        "            SABlock(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.expand_channels,\n",
        "                kernel_size=3,\n",
        "                stride=2 if self.is_downsize else 1,\n",
        "                padding=1,\n",
        "                groups=self.in_channels,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.expand_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pointwise = nn.Sequential(\n",
        "            CABlock(in_channels=self.expand_channels, ratio=8),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.expand_channels,\n",
        "                out_channels=self.freeze_channels,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.freeze_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.depthwise_freeze = nn.Sequential(\n",
        "            SABlock(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.freeze_channels,\n",
        "                out_channels=self.freeze_channels,\n",
        "                kernel_size=3,\n",
        "                stride=2 if self.is_downsize else 1,\n",
        "                padding=1,\n",
        "                groups=self.freeze_channels,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.freeze_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.skip_att = SABlock()\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        inputs = x\n",
        "        x = self.depthwise_expand(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.depthwise_freeze(x)\n",
        "\n",
        "        if not(self.is_downsize) and x.shape == inputs.shape:\n",
        "            inputs = self.skip_att(inputs)\n",
        "            x = inputs + x\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_divisible(self, out_channels, groups):\n",
        "        ratio = out_channels // groups\n",
        "        return int(groups * ratio)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "class DPDBlockV3(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        expand_channels,\n",
        "        freeze_channels,\n",
        "        is_downsize=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.expand_channels = self._make_divisible(expand_channels, in_channels)\n",
        "        self.freeze_channels = freeze_channels\n",
        "        self.is_downsize = is_downsize\n",
        "\n",
        "        self.depthwise_expand = nn.Sequential(\n",
        "            SABlock(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.expand_channels,\n",
        "                kernel_size=3,\n",
        "                stride=2 if self.is_downsize else 1,\n",
        "                padding=1,\n",
        "                groups=self.in_channels,\n",
        "                bias=True\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.expand_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pointwise = nn.Sequential(\n",
        "            LCABlock(in_channels=self.expand_channels),\n",
        "            SeperableGhostModule(\n",
        "                in_channels=self.expand_channels,\n",
        "                out_channels=self.freeze_channels,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=True\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.depthwise_freeze = nn.Sequential(\n",
        "            SABlock(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.freeze_channels,\n",
        "                out_channels=self.freeze_channels,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "                groups=self.freeze_channels,\n",
        "                bias=True\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.freeze_channels),\n",
        "        )\n",
        "\n",
        "        self.drop_path = DropPath(0.2)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        inputs = x\n",
        "        x = self.depthwise_expand(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.depthwise_freeze(x)\n",
        "\n",
        "        if not(self.is_downsize) and x.shape == inputs.shape:\n",
        "            x = x + self.drop_path(inputs)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_divisible(self, out_channels, groups):\n",
        "        ratio = out_channels // groups\n",
        "        return int(groups * ratio)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "class DPDBlockV2(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        expand_channels,\n",
        "        freeze_channels,\n",
        "        is_downsize=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.expand_channels = self._make_divisible(expand_channels, in_channels)\n",
        "        self.freeze_channels = freeze_channels\n",
        "        self.is_downsize = is_downsize\n",
        "\n",
        "        self.depthwise_expand = nn.Sequential(\n",
        "            SABlock(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.expand_channels,\n",
        "                kernel_size=3,\n",
        "                stride=2 if self.is_downsize else 1,\n",
        "                padding=1,\n",
        "                groups=self.in_channels,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.expand_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pointwise = nn.Sequential(\n",
        "            LCABlock(in_channels=self.expand_channels),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.expand_channels,\n",
        "                out_channels=self.freeze_channels,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.freeze_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.depthwise_freeze = nn.Sequential(\n",
        "            SABlock(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.freeze_channels,\n",
        "                out_channels=self.freeze_channels,\n",
        "                kernel_size=3,\n",
        "                stride=2 if self.is_downsize else 1,\n",
        "                padding=1,\n",
        "                groups=self.freeze_channels,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.freeze_channels),\n",
        "        )\n",
        "\n",
        "        self.drop_path = DropPath(0.2)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        inputs = x\n",
        "        x = self.depthwise_expand(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.depthwise_freeze(x)\n",
        "\n",
        "        if not(self.is_downsize) and x.shape == inputs.shape:\n",
        "            x = x + self.drop_path(inputs)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_divisible(self, out_channels, groups):\n",
        "        ratio = out_channels // groups\n",
        "        return int(groups * ratio)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)"
      ],
      "metadata": {
        "id": "-cdWNC86Dqru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SABlock(nn.Module):\n",
        "\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "        self.conv2d = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        avg_pool = torch.mean(inputs, dim=1, keepdim=True)\n",
        "        max_pool, _ = torch.max(inputs, dim=1, keepdim=True)\n",
        "\n",
        "        x = torch.cat([avg_pool, max_pool], dim=1)\n",
        "        x = self.conv2d(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x * inputs\n",
        "\n",
        "class LCABlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.depthwise = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=in_channels,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "            groups=in_channels,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        self.gamma = nn.Parameter(torch.zeros(1, 1, 1, in_channels))\n",
        "        self.beta = nn.Parameter(torch.zeros(1, 1, 1, in_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        group_norm_x = torch.norm(x, p=2, dim=(1, 2), keepdim=True)\n",
        "        relative_important_x = group_norm_x / (group_norm_x.mean(dim=-1, keepdim=True) + 1e-6)\n",
        "        x = self.gamma * (x * relative_important_x) + self.beta + x\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        return x\n",
        "\n",
        "class CABlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super().__init__()\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.block = nn.Sequential(nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
        "                               nn.ReLU(),\n",
        "                               nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False))\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.block(self.avg_pool(x))\n",
        "        max_out = self.block(self.max_pool(x))\n",
        "        out = avg_out + max_out\n",
        "\n",
        "        return self.sigmoid(out) * x"
      ],
      "metadata": {
        "id": "a4ebphu9F8Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BACKBONE"
      ],
      "metadata": {
        "id": "8gPbJCeeF-dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torchvision\n",
        "import torch\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BackboneFactory:\n",
        "    @staticmethod\n",
        "    def create_model(name: str):\n",
        "        if name == \"mobile_13th_block\":\n",
        "            backbone = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "            return_nodes = {\n",
        "                \"features.13\": \"expand\"\n",
        "            }\n",
        "\n",
        "            return create_feature_extractor(backbone, return_nodes=return_nodes)\n",
        "\n",
        "        elif name == \"mobile_10th_block\":\n",
        "            backbone = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "            return_nodes = {\n",
        "                \"features.10\": \"expand\"\n",
        "            }\n",
        "\n",
        "            return create_feature_extractor(backbone, return_nodes=return_nodes)\n",
        "\n",
        "        elif name == \"mobile_6th_block\":\n",
        "            backbone = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "            return_nodes = {\n",
        "                \"features.6\": \"expand\"\n",
        "            }\n",
        "\n",
        "            return create_feature_extractor(backbone, return_nodes=return_nodes)\n",
        "\n",
        "        elif name == \"mobile_expand_relu\":\n",
        "            backbone = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "            return_nodes = {\n",
        "                    \"features.14.conv.0\": \"expand\"\n",
        "            }\n",
        "\n",
        "            return create_feature_extractor(backbone, return_nodes=return_nodes)\n",
        "\n",
        "        elif name == \"ghostnet\":\n",
        "            backbone = timm.create_model('ghostnet_100', pretrained=True)\n",
        "            backbone.classifier = nn.Sequential(\n",
        "                nn.Linear(1280, 1),\n",
        "            )\n",
        "\n",
        "            return create_feature_extractor(backbone, return_nodes=return_nodes)\n",
        "\n",
        "        elif name == \"mobilenet\":\n",
        "            backbone = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "            backbone.classifier[1] = nn.Sequential(\n",
        "                nn.Linear(1280, 1),\n",
        "            )\n",
        "\n",
        "            return create_feature_extractor(backbone, return_nodes=return_nodes)\n",
        "        elif name == \"mobile_v2_cls\":\n",
        "            backbone = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "            backbone.classifier[1] = nn.Sequential(\n",
        "                nn.Linear(1280, 4),\n",
        "            )\n",
        "            return backbone\n",
        "            # return create_feature_extractor(backbone, return_nodes=return_nodes)\n",
        "\n",
        "        # elif name == \"shufflenet\":\n",
        "        #     backbone = torchvision.models.shufflenet_v2_x1_0(pretrained=True)\n",
        "        #     backbone.fc = nn.Sequential(\n",
        "        #         nn.Linear(1024, 1),\n",
        "        #     )\n",
        "\n",
        "        #     return create_feature_extractor(backbone, return_nodes=return_nodes)\n",
        "\n",
        "        elif name == \"mobilev3\":\n",
        "            backbone = torchvision.models.mobilenet_v3_small(pretrained=True)\n",
        "            backbone.classifier[3] = nn.Sequential(\n",
        "                nn.Linear(1024, 1),\n",
        "            )\n",
        "            return backbone\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"There is no model whose name is {name}.\")\n"
      ],
      "metadata": {
        "id": "Wm5S6BxWG2Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GHOST MODULE"
      ],
      "metadata": {
        "id": "qaRZfzygGIEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SeperableGhostModule(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        bias=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.primary = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=in_channels,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "                groups=in_channels,\n",
        "                bias=bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels//2,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels//2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.cheap = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=out_channels//2,\n",
        "                out_channels=out_channels//2,\n",
        "                kernel_size=kernel_size,\n",
        "                stride=stride,\n",
        "                padding=kernel_size//2,\n",
        "                groups=out_channels//2,\n",
        "                bias=bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels//2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.primary(x)\n",
        "        x_cheap = self.cheap(x)\n",
        "        x = torch.concat([x, x_cheap], axis=1)\n",
        "        return x\n",
        "\n",
        "class GhostModule(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        bias=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.primary = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels//2,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels//2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.cheap = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=out_channels//2,\n",
        "                out_channels=out_channels//2,\n",
        "                kernel_size=kernel_size,\n",
        "                stride=stride,\n",
        "                padding=kernel_size//2,\n",
        "                groups=out_channels//2,\n",
        "                bias=bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels//2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.primary(x)\n",
        "        x_cheap = self.cheap(x)\n",
        "        x = torch.concat([x, x_cheap], axis=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "R5wrHKfnGCMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SeperableConv2d(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        padding,\n",
        "        bias=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "TKopleBjGSXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationFunction(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.name = self.__class__.__name__\n",
        "        self.config = {\"name\": self.name}\n",
        "class ReLU_04(ActivationFunction):\n",
        "    def forward(self, x):\n",
        "        x = x * (x > 0).float()\n",
        "        # * (x > 0) if true, return 1, therefore x * 1 = x, x <= 0 true then x > 0 = 1 then it is 0\n",
        "        # If x >=4 then (x >= 4) = 1 and (x < 4) = 0; then it choose one of x or 4\n",
        "        return ((x >= 4) * 4 + (x < 4) * x).float()"
      ],
      "metadata": {
        "id": "YZWCS5qvGYVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr, pearsonr\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# from pl_trainer.shuffle_trainer import MobileNet, QualityNet, InferenceModel\n",
        "\n",
        "class DMGNet(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = BackboneFactory.create_model(\"mobile_torchvision_13\")\n",
        "        # self.backbone = net\n",
        "        # for param in self.backbone.parameters():\n",
        "        #     param.require_grad = False\n",
        "\n",
        "#         for module in self.backbone.modules():\n",
        "#             if isinstance(module, nn.BatchNorm2d):\n",
        "#                 if hasattr(module, 'weight'):\n",
        "#                     module.weight.requires_grad_(False)\n",
        "#                 if hasattr(module, 'bias'):\n",
        "#                     module.bias.requires_grad_(False)\n",
        "# #                 module.affine = False\n",
        "#                 module.eval()\n",
        "\n",
        "#         self.init_conv = nn.Sequential(\n",
        "#             nn.Conv2d(\n",
        "#                 in_channels=576,\n",
        "#                 out_channels=64,\n",
        "#                 kernel_size=1,\n",
        "#                 stride=1,\n",
        "#                 bias=False\n",
        "#             ),\n",
        "#             nn.BatchNorm2d(64)\n",
        "#         )\n",
        "\n",
        "#         self.dpd_blocks = nn.Sequential(\n",
        "#             DPDBlockV3(64, 384, 96, False),\n",
        "#             DPDBlockV3(96, 576, 160, True),\n",
        "#             DPDBlockV3(160, 960, 160, False),\n",
        "#             DPDBlockV3(160, 960, 320, False)\n",
        "#         )\n",
        "\n",
        "        self.init_conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=576,\n",
        "                out_channels=32,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(32)\n",
        "        )\n",
        "\n",
        "        self.dpd_blocks = nn.Sequential(\n",
        "            DPDBlockV3(32, 192, 48, False),\n",
        "            DPDBlockV3(48, 288, 64, True),\n",
        "            DPDBlockV3(64, 384, 64, False),\n",
        "            DPDBlockV3(64, 386, 96, False)\n",
        "        )\n",
        "\n",
        "#         self.smooth_conv = nn.Sequential(\n",
        "#             nn.Conv2d(\n",
        "#                 in_channels=320,\n",
        "#                 out_channels=256,\n",
        "#                 kernel_size=1,\n",
        "#                 stride=1,\n",
        "#                 bias=False\n",
        "#             ),\n",
        "#             nn.BatchNorm2d(256),\n",
        "#             nn.ReLU()\n",
        "#         )\n",
        "\n",
        "        self.smooth_conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=96,\n",
        "                out_channels=144,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(144),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(144, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.loss_fn = torch.nn.MSELoss()\n",
        "        self.test_metric = torch.nn.L1Loss()\n",
        "        self.preds_epoch = []\n",
        "        self.labels_epoch = []\n",
        "        self.val_preds_epoch = []\n",
        "        self.val_labels_epoch = []\n",
        "        # self.test_preds_epoch = []\n",
        "        # self.test_labels_epoch = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = x[\"expand\"]\n",
        "        x = self.init_conv(x)\n",
        "        x = self.dpd_blocks(x)\n",
        "        x = self.smooth_conv(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_top_layers(self):\n",
        "        return nn.Sequential(\n",
        "            self.dpd_blocks,\n",
        "            self.smooth_conv,\n",
        "            self.gap,\n",
        "            self.classifier\n",
        "        )\n",
        "\n",
        "#     def get_backbone(self):\n",
        "#         return nn.Sequential(\n",
        "#             self.backbone,\n",
        "#             self.init_conv\n",
        "#         )\n",
        "    def get_backbone_feature(self, x):\n",
        "        self.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            x = self.backbone(x)\n",
        "            x = x[\"expand\"]\n",
        "            x = self.init_conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=20, min_lr=1e-7, verbose=True)\n",
        "\n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_srocc\"}\n",
        "\n",
        "    def _calculate_loss(self, batch):\n",
        "        image, rating = batch\n",
        "        y_pred = self.forward(image)\n",
        "        y_pred = y_pred[:, 0]\n",
        "\n",
        "        loss = self.loss_fn(y_pred, rating)\n",
        "        self.preds_epoch = np.append(self.preds_epoch, y_pred.cpu().detach().numpy())\n",
        "        self.labels_epoch = np.append(self.labels_epoch, rating.cpu().detach().numpy())\n",
        "        rho_s, _ = spearmanr(np.squeeze(self.preds_epoch), np.squeeze(self.labels_epoch))\n",
        "        rho_p, _ = pearsonr(np.squeeze(self.preds_epoch), np.squeeze(self.labels_epoch))\n",
        "        # print(rho_s)\n",
        "        # self.log(\"train_srocc\", rho_s)\n",
        "        # self.log(\"train_plcc\", rho_p)\n",
        "\n",
        "        return loss, rho_s, rho_p\n",
        "\n",
        "    def _calculate_test_loss(self, batch):\n",
        "        image, rating = batch\n",
        "        y_pred = self.forward(image)\n",
        "        y_pred = y_pred[:, 0]\n",
        "\n",
        "        loss = self.test_metric(y_pred, rating)\n",
        "        self.val_preds_epoch = np.append(self.val_preds_epoch, y_pred.cpu().detach().numpy())\n",
        "        self.val_labels_epoch = np.append(self.val_labels_epoch, rating.cpu().detach().numpy())\n",
        "        rho_s, _ = spearmanr(np.squeeze(self.val_preds_epoch), np.squeeze(self.val_labels_epoch))\n",
        "        rho_p, _ = pearsonr(np.squeeze(self.val_preds_epoch), np.squeeze(self.val_labels_epoch))\n",
        "\n",
        "        return loss, rho_s, rho_p\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        loss, rho_s, rho_p = self._calculate_loss(batch)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_srocc\", rho_s, prog_bar=True)\n",
        "        self.log(\"train_plcc\", rho_p, prog_bar=True)\n",
        "        return {\"loss\": loss, \"srocc\": rho_s, \"plcc\": rho_p}\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        rho_s, _ = spearmanr(np.squeeze(self.preds_epoch), np.squeeze(self.labels_epoch))\n",
        "        rho_p, _ = pearsonr(np.squeeze(self.preds_epoch), np.squeeze(self.labels_epoch))\n",
        "        self.log(\"train_srocc_epoch\", rho_s)\n",
        "        self.log(\"train_plcc_epoch\", rho_p)\n",
        "        self.preds_epoch = []\n",
        "        self.labels_epoch = []\n",
        "        print(f\"Train SROCC = {rho_s} and Train PLCC = {rho_p}\")\n",
        "\n",
        "    def validation_step(self, batch, batch_index):\n",
        "        loss, rho_s, rho_p = self._calculate_test_loss(batch)\n",
        "        self.log(\"val_loss\", loss)\n",
        "        self.log(\"val_srocc\", rho_s)\n",
        "        self.log(\"val_plcc\", rho_p)\n",
        "        return {\"loss\": loss, \"srocc\": rho_s, \"plcc\": rho_p}\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        rho_s, _ = spearmanr(np.squeeze(self.val_preds_epoch), np.squeeze(self.val_labels_epoch))\n",
        "        rho_p, _ = pearsonr(np.squeeze(self.val_preds_epoch), np.squeeze(self.val_labels_epoch))\n",
        "        self.log(\"val_srocc_epoch\", rho_s)\n",
        "        self.log(\"val_plcc_epoch\", rho_p)\n",
        "        self.val_preds_epoch = []\n",
        "        self.val_labels_epoch = []\n",
        "        print(f\"Train SROCC = {rho_s} and Train PLCC = {rho_p}\")\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        rho_s, _ = spearmanr(np.squeeze(self.val_preds_epoch), np.squeeze(self.val_labels_epoch))\n",
        "        rho_p, _ = pearsonr(np.squeeze(self.val_preds_epoch), np.squeeze(self.val_labels_epoch))\n",
        "        mse = mean_squared_error(np.squeeze(self.val_preds_epoch), np.squeeze(self.val_labels_epoch))\n",
        "        mae = mean_absolute_error(np.squeeze(self.val_preds_epoch), np.squeeze(self.val_labels_epoch))\n",
        "        self.log(\"test_srocc_epoch\", rho_s)\n",
        "        self.log(\"test_plcc_epoch\", rho_p)\n",
        "        self.log(\"test_mse\", mse)\n",
        "        self.log(\"test_mae\", mae)\n",
        "        print(np.squeeze(self.val_preds_epoch))\n",
        "        pd.DataFrame.from_dict({\n",
        "            \"preds\":  np.squeeze(self.val_preds_epoch),\n",
        "            \"targets\": np.squeeze(self.val_labels_epoch)\n",
        "        }).to_csv(\"pred_score.csv\", index=False)\n",
        "\n",
        "        self.val_preds_epoch = []\n",
        "        self.val_labels_epoch = []\n",
        "        print(f\"Test SROCC = {rho_s}, test PLCC = {rho_p}, test MSE = {mse} and test MAE = {mae}\")\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_index):\n",
        "        loss, rho_s, rho_p = self._calculate_test_loss(batch)\n",
        "\n",
        "        self.log(\"test_loss\", loss)\n",
        "        self.log(\"test_srocc\", rho_s)\n",
        "        self.log(\"test_plcc\", rho_p)\n",
        "        return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "EWVJDkrDDq1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import torchvision\n",
        "from torchmetrics import F1Score, Accuracy\n",
        "\n",
        "class InferenceModel(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.focal_loss = torch.nn.CrossEntropyLoss(torch.tensor([50., 9., 3., 1.88, 50.]).to(\"cuda:1\"))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "\n",
        "class MobileNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = BackboneFactory.create_model(\"mobile_v2_cls\")\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        return x\n",
        "\n",
        "class QualityNet(pl.LightningModule):\n",
        "    def __init__(self, model=MobileNet()):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "        self.focal_loss = torch.nn.CrossEntropyLoss(torch.tensor([50., 9., 3., 1.88, 50.]).to(\"cuda:1\"))\n",
        "        self.f1_train = F1Score(task=\"multiclass\", num_classes=5, average=\"macro\")\n",
        "        self.f1_val = F1Score(task=\"multiclass\", num_classes=5, average=\"macro\")\n",
        "        self.acc_train = Accuracy(task=\"multiclass\", num_classes=5)\n",
        "        self.acc_val = Accuracy(task=\"multiclass\", num_classes=5)\n",
        "        self.validation_step_outputs = []\n",
        "\n",
        "    def forward(self, x, label):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-5)\n",
        "        # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=7, min_lr=1e-7, verbose=True)\n",
        "\n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_acc\"}\n",
        "\n",
        "    def _calculate_train_acc(self, batch):\n",
        "        images, labels = batch\n",
        "\n",
        "        logits = self.forward(images, labels)\n",
        "        preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        f1 = self.f1_train(preds, labels)\n",
        "        acc = self.acc_train(labels, preds)\n",
        "\n",
        "        return acc, f1\n",
        "\n",
        "    def _calculate_val_acc(self, batch):\n",
        "        images, labels = batch\n",
        "\n",
        "        logits = self.forward(images, labels)\n",
        "        preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        self.f1_val.update(preds, labels)\n",
        "        self.acc_val.update(labels, preds)\n",
        "\n",
        "    def _calculate_loss(self, batch):\n",
        "        image, label = batch\n",
        "        y_pred = self.forward(image, label)\n",
        "\n",
        "        loss = self.focal_loss(y_pred, label)\n",
        "        return loss\n",
        "\n",
        "    def _calculate_test_loss(self, batch):\n",
        "        image, label = batch\n",
        "        y_pred = self.forward(image, label)\n",
        "\n",
        "        loss = self.focal_loss(y_pred, label)\n",
        "        return loss, y_pred\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        image, label = batch\n",
        "        loss, y_pred = self._calculate_test_loss(batch)\n",
        "        acc, f1 = self._calculate_train_acc(batch)\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_f1\", f1, prog_bar=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True)\n",
        "\n",
        "        return {\"loss\": loss, \"predictions\": y_pred, \"labels\": label}\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        # compute metrics\n",
        "        train_accuracy = self.acc_train.compute()\n",
        "        train_f1 = self.f1_train.compute()\n",
        "        # log metrics\n",
        "        self.log(\"epoch_train_accuracy\", train_accuracy)\n",
        "        self.log(\"epoch_train_f1\", train_f1)\n",
        "        # reset all metrics\n",
        "        self.acc_train.reset()\n",
        "        self.f1_train.reset()\n",
        "        print(f\"\\ntraining accuracy: {train_accuracy:.4}, \"\\\n",
        "        f\"f1: {train_f1:.4}\")\n",
        "\n",
        "#         preds = []\n",
        "#         labels = []\n",
        "\n",
        "#         for output in training_step_outputs:\n",
        "#             logits = output['predictions']\n",
        "#             preds += torch.argmax(logits, dim=-1).cpu().numpy().tolist()\n",
        "#             labels += output['labels'].cpu().numpy().tolist()\n",
        "\n",
        "        # print(classification_report(labels, preds))\n",
        "\n",
        "    def validation_step(self, batch, batch_index):\n",
        "        image, label = batch\n",
        "        loss, y_pred = self._calculate_test_loss(batch)\n",
        "        self._calculate_val_acc(batch)\n",
        "\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "        return {\"val_loss\": loss, \"predictions\": y_pred, \"labels\": label}\n",
        "\n",
        "    # Validation epoch end\n",
        "    def on_validation_epoch_end(self):\n",
        "        val_accuracy = self.acc_val.compute()\n",
        "        val_f1 = self.f1_val.compute()\n",
        "        # log metrics\n",
        "        self.log(\"val_acc\", val_accuracy)\n",
        "        self.log(\"val_f1\", val_f1)\n",
        "        # reset all metrics\n",
        "        self.acc_val.reset()\n",
        "        self.f1_val.reset()\n",
        "        print(f\"\\nValidation accuracy: {val_accuracy:.4} \"\\\n",
        "        f\"f1: {val_f1:.4}\")\n",
        "\n",
        "#         preds = []\n",
        "#         labels = []\n",
        "\n",
        "#         for output in self.validation_step_outputs:\n",
        "#             logits = output['predictions']\n",
        "#             preds += torch.argmax(logits, dim=-1).cpu().numpy().tolist()\n",
        "#             labels += output['labels'].cpu().numpy().tolist()\n",
        "\n",
        "#         print(classification_report(labels, preds))\n",
        "\n",
        "    def test_step(self, batch, batch_index):\n",
        "        loss = self._calculate_loss(batch)\n",
        "        self._calculate_val_acc(batch)\n",
        "\n",
        "        # self.log(\"test_loss\", loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        val_accuracy = self.acc_val.compute()\n",
        "        val_f1 = self.f1_val.compute()\n",
        "        # log metrics\n",
        "        self.log(\"val_acc\", val_accuracy)\n",
        "        self.log(\"val_f1\", val_f1)\n",
        "        # reset all metrics\n",
        "        self.acc_val.reset()\n",
        "        self.f1_val.reset()\n",
        "        print(f\"\\nTest accuracy: {val_accuracy:.4} \"\\\n",
        "        f\"Test f1: {val_f1:.4}\")\n",
        "\n",
        "class ShuffleNet(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "#         # ShuffleNet\n",
        "#         self.backbone = BackboneFactory.create_model(\"shuffle\")\n",
        "\n",
        "#         GhostNet\n",
        "#         self.backbone = BackboneFactory.create_model(\"ghost\")\n",
        "#         self.backbone.classifier = nn.Sequential(\n",
        "#             nn.Linear(1280, 1)\n",
        "\n",
        "#         )\n",
        "        #MobileNetV3\n",
        "        self.backbone = BackboneFactory.create_model(\"mobilev3\")\n",
        "#         MobileNetV2\n",
        "        # self.backbone = BackboneFactory.create_model(\"mobile\")\n",
        "\n",
        "        # MobileDPD10\n",
        "#         self.backbone = MobileDPD10()\n",
        "\n",
        "        # MobileDPD13\n",
        "#         self.backbone = MobileDPD13()\n",
        "        # MobileDPDBig\n",
        "#         self.backbone = MobileDPDBig()\n",
        "\n",
        "        self.loss_fn = torch.nn.L1Loss()\n",
        "        self.test_metric = torch.nn.L1Loss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "#         x = x[\"expand\"]\n",
        "#         x = self.init_conv(x)\n",
        "#         x = self.dpd_blocks(x)\n",
        "#         x = self.smooth_conv(x)\n",
        "#         x = self.gap(x)\n",
        "#         x = self.classifier(x)\n",
        "#         x = torch.where(x > 4, 4, x)\n",
        "#         x = torch.where(x < 0, 0, x)\n",
        "\n",
        "        return x * 4\n",
        "\n",
        "    def get_top_layers(self):\n",
        "        return nn.Sequential(\n",
        "            self.dpd_blocks,\n",
        "            self.smooth_conv,\n",
        "            self.gap,\n",
        "            self.classifier\n",
        "        )\n",
        "\n",
        "#     def get_backbone(self):\n",
        "#         return nn.Sequential(\n",
        "#             self.backbone,\n",
        "#             self.init_conv\n",
        "#         )\n",
        "    def get_backbone_feature(self, x):\n",
        "        self.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            x = self.backbone(x)\n",
        "            x = x[\"expand\"]\n",
        "            x = self.init_conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=7, min_lr=1e-7, verbose=True)\n",
        "\n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
        "\n",
        "    def _calculate_loss(self, batch):\n",
        "        image, rating = batch\n",
        "        y_pred = self.forward(image)\n",
        "        y_pred = y_pred[:, 0]\n",
        "\n",
        "        loss = self.loss_fn(y_pred, rating)\n",
        "        return loss\n",
        "\n",
        "    def _calculate_test_loss(self, batch):\n",
        "        image, rating = batch\n",
        "        y_pred = self.forward(image)\n",
        "        y_pred = y_pred[:, 0]\n",
        "\n",
        "        loss = self.test_metric(y_pred, rating)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        loss = self._calculate_loss(batch)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_index):\n",
        "        loss = self._calculate_test_loss(batch)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "        return {\"val_loss\": loss}\n",
        "\n",
        "    def test_step(self, batch, batch_index):\n",
        "        loss = self._calculate_test_loss(batch)\n",
        "\n",
        "        self.log(\"test_loss\", loss)\n",
        "\n",
        "        return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "ERtkc5uIDt5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import os\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "\n",
        "parent_dir = \"/data/image_review/data/koniq10/1024x768\"\n",
        "train_csv_path = \"/data/image_review/data/koniq10/train_koniq.csv\"\n",
        "val_csv_path = \"/data/image_review/data/koniq10/val_koniq.csv\"\n",
        "test_csv_path = \"/dataimage_review/data/koniq10/test_koniq.csv\"\n",
        "\n",
        "quality_datamodule = QualityDataModule(parent_dir, train_csv_path, val_csv_path, batch_size=16)\n",
        "# wandb_logger = WandbLogger(name=\"mobile_dpd_512x384\", project=\"koniq10\", log_model=\"all\")\n",
        "# wandb_logger.experiment.config[\"batch_size\"] = 16\n",
        "\n",
        "# net = InferenceModel(MobileNet())\n",
        "# checkpoint_path = \"weights/weight_koniq/mobile_koniq10_reduce_cls_epoch=32_val_f1=0.5576_val_acc=0.7440.ckpt\"\n",
        "# checkpoint_dict = torch.load(checkpoint_path, map_location=\"cuda:1\")[\"state_dict\"].keys()\n",
        "# # print(checkpoint_dict)\n",
        "# # del checkpoint_dict[\"focal_loss.weight\"]\n",
        "# net.load_state_dict(torch.load(checkpoint_path, map_location=\"cuda:1\")[\"state_dict\"])\n",
        "# net = net.model.backbone\n",
        "# return_nodes = {\n",
        "#     \"features.14.conv.0\": \"expand\"\n",
        "# }\n",
        "# net = create_feature_extractor(net, return_nodes=return_nodes)\n",
        "# print(net.model.backbone)\n",
        "model = DMGNet.load_from_checkpoint(\n",
        "    \"weights/weight_koniq/mobiledpd_koniq10_reduce_epoch=58_val_srocc=0.9055_val_plcc=0.9198.ckpt\")\n",
        "\n",
        "# checkpoint_callback = ModelCheckpoint(\n",
        "#     dirpath=\"weights/weight_koniq\",\n",
        "#     filename='mobiledpd_koniq10_reduce_{epoch}_{val_srocc:.4f}_{val_plcc:.4f}',\n",
        "#     save_top_k=1,\n",
        "#     verbose=True,\n",
        "#     monitor=\"val_srocc\",\n",
        "#     mode=\"max\",\n",
        "# )\n",
        "\n",
        "# trainer = pl.Trainer(accelerator=\"gpu\",\n",
        "#                      logger=wandb_logger,\n",
        "#                      devices=[1],\n",
        "#                      max_epochs=1000,\n",
        "#                      callbacks=[checkpoint_callback])\n",
        "# #  accumulate_grad_batches=1\n",
        "\n",
        "trainer = pl.Trainer(accelerator=\"gpu\",\n",
        "                     devices=[1])\n",
        "\n",
        "# # print(\"Training\")\n",
        "# trainer.fit(model, quality_datamodule)\n",
        "test_data = QualityDataset(parent_dir, test_csv_path)\n",
        "trainer.test(model, dataloaders=DataLoader(test_data, batch_size=32, num_workers=12))\n",
        "\n",
        "# wandb.finish()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "avRGKmYjD0lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sWbKR3K1H6u4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}