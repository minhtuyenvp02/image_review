{
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "id": "GBnqzZ0p6A_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install torchtext\n",
        "!pip install matplotlib\n",
        "!pip install torchvision\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install timm\n",
        "!pip install scikit_learn\n",
        "!pip install pandas\n",
        "!pip install opencv_contrib_python\n",
        "!pip install opencv_python_headless\n",
        "! pip install torchsummary\n",
        "! pip install einops\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "e_E9VNolkpiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# setup path to data folder\n",
        "data_path = Path(\"/content/drive/MyDrive/data\")\n",
        "# print(data_path)\n",
        "image_path = data_path / \"image-rv-70k-float\"\n",
        "print(image_path)\n",
        "\n",
        "# If the image folder doesn't exist, dowload it and prepare it...\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory exists. \")\n",
        "else:\n",
        "  print(f\"Did not find {image_path} directory, creating one...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "3aS-bbm2MaHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import zipfile\n",
        "# with zipfile.ZipFile(os.path.join(data_path, \"/content/drive/MyDrive/Data_NAVER_Image_Review/data70k_float.zip\"), \"r\") as zip_ref:\n",
        "#   print(\"Unzipping data....\")\n",
        "#   zip_ref.extractall(image_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "4zP8iHghMM7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Helper function\n",
        "import os\n",
        "images = []\n",
        "labels = []\n",
        "def walk_through_dir(dir_path):\n",
        "  '''\n",
        "    walk through dir_path, returning its contents\n",
        "    Args:\n",
        "      dir_path(str or pathlib.Path): target directory\n",
        "    Return\n",
        "      A orint out of:\n",
        "          number of subdirctories in dir_path\n",
        "          number of image (files) in each subdirectory\n",
        "          number of each subdirectory\n",
        "  '''\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    index = dirpath.rindex('/')\n",
        "    number_string = dirpath[index+1:]\n",
        "    print(number_string)\n",
        "    if number_string == 'train' or number_string == 'test':\n",
        "      pass\n",
        "    else:\n",
        "      labels.append(float(dirpath[index+1:]))\n",
        "      images.append(len(filenames))\n",
        "    # print(f\"There are {len(dirnames)} directoires and {len(filenames)} images in '{dirpath}'\")\n",
        ""
      ],
      "metadata": {
        "id": "eh_FN7rwMKBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(\"/content/drive/MyDrive/Data_NAVER_Image_Review/image-rv-70k-float/data70k/train\")"
      ],
      "metadata": {
        "id": "csXVsE6CNpKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dữ liệu nhãn và số lượng tương ứng\n",
        "# labels = [0, 1, 2, 3, 4]\n",
        "# counts = [2659, 6976, 3881, 473, 11]\n",
        "\n",
        "# Màu sắc cho cột\n",
        "# colors = ['#FF6F61', '#6B5B95', '#88B04B', '#955251', '#B565A7']\n",
        "\n",
        "# Vẽ biểu đồ cột với màu sắc\n",
        "plt.bar(labels, images)\n",
        "\n",
        "# Đặt tên cho trục x và y\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Number of image')\n",
        "\n",
        "# Đặt tiêu đề cho biểu đồ\n",
        "plt.title('Distribution of test set')\n",
        "\n",
        "# Hiển thị biểu đồ\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wwI3PWiH1Sbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import albumentations as A\n",
        "\n",
        "import timm\n",
        "from pytorch_lightning.utilities.model_summary import ModelSummary, summarize\n",
        "from pytorch_lightning.tuner.tuning import Tuner\n",
        "from einops.layers.torch import Rearrange\n",
        "from torchmetrics import ConfusionMatrix\n",
        "from scipy.ndimage import gaussian_filter1d, convolve1d\n",
        "from scipy.signal.windows import triang\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, RichProgressBar\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from collections import OrderedDict\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import shutil\n",
        "\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lxavXeLVYzCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lds_kernel_window(kernel, ks, sigma):\n",
        "    assert kernel in ['gaussian', 'triang', 'laplace']\n",
        "    half_ks = (ks - 1) // 2\n",
        "    if kernel == 'gaussian':\n",
        "        base_kernel = [0.] * half_ks + [1.] + [0.] * half_ks\n",
        "        kernel_window = gaussian_filter1d(base_kernel, sigma=sigma) / max(gaussian_filter1d(base_kernel, sigma=sigma))\n",
        "    elif kernel == 'triang':\n",
        "        kernel_window = triang(ks)\n",
        "    else:\n",
        "        laplace = lambda x: np.exp(-abs(x) / sigma) / (2. * sigma)\n",
        "        kernel_window = list(map(laplace, np.arange(-half_ks, half_ks + 1))) / max(map(laplace, np.arange(-half_ks, half_ks + 1)))\n",
        "\n",
        "    return kernel_window\n",
        "\n",
        "class Naver2Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self, root_dir, mode = 'train',\n",
        "        transform = None,\n",
        "        reweight = \"sqrt_inv\", resolution = 0.1,\n",
        "        max_target=51, lds=False, lds_kernel='gaussian', lds_ks=5, lds_sigma=2,\n",
        "        label_type = 'int',\n",
        "    ):\n",
        "        super().__init__()\n",
        "        print(\"Collecting data at: \", root_dir)\n",
        "        self.root_dir = f\"{root_dir}/{mode}\" #  + mode + '/'\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "        self.img_names, self.labels = [], []\n",
        "        # self.set_labels = [0.0]\n",
        "        self.set_labels = sorted([float(folder.name) for folder in os.scandir(self.root_dir) if folder.is_dir()])\n",
        "        self.label_type = label_type\n",
        "        self.lds = lds\n",
        "\n",
        "        for label in self.set_labels:\n",
        "            for name in os.listdir(f\"{self.root_dir}/{label}\"):\n",
        "                self.img_names.append(name)\n",
        "                self.labels.append(float(label))\n",
        "\n",
        "        # self.img_names = self.img_names[0: 20]\n",
        "        # self.labels = self.labels[0: 20]\n",
        "        if label_type == 'int':\n",
        "            self.set_labels = sorted([round(label) for label in self.set_labels])\n",
        "\n",
        "        # if mode == \"train\":\n",
        "        self.weights = self._prepare_weights(reweight, resolution = resolution,\n",
        "                                             max_target=max_target,\n",
        "                                             lds=lds, lds_kernel=lds_kernel, lds_ks=lds_ks, lds_sigma=lds_sigma)\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(f\"{self.root_dir}/{label}/{self.img_names[idx]}\")\n",
        "        if self.label_type == 'int':\n",
        "            label = round(self.labels[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = torch.FloatTensor([label])\n",
        "        if self.lds == True:\n",
        "            weight = torch.FloatTensor([self.weights[idx]])\n",
        "            return image, label, weight\n",
        "        else:\n",
        "            return image, label\n",
        "\n",
        "\n",
        "    def _prepare_weights(self, reweight, resolution = 0.1, max_target=51, lds=False, lds_kernel='gaussian', lds_ks=5, lds_sigma=2):\n",
        "        assert reweight in {'none', 'inverse', 'sqrt_inv'}\n",
        "        assert reweight != 'none' if lds else True, \\\n",
        "            \"Set reweight to \\'sqrt_inv\\' (default) or \\'inverse\\' when using LDS\"\n",
        "        print(max_target)\n",
        "\n",
        "\n",
        "        labels = self.labels # self.data[:, -1].tolist()\n",
        "        labels = list(map(lambda x: float(format(round(x / resolution) * resolution, '.1f')), labels))\n",
        "        value_dict = {x: 0 for x in set(labels)}\n",
        "        set_labels_smooth = set(labels)\n",
        "        # value_dict = {round(x, 1): 0 for x in np.arange(0, 4 + resolution, resolution)}\n",
        "\n",
        "        # mbr\n",
        "        for label in labels:\n",
        "            if self.label_type == 'int':\n",
        "                label = round(label)\n",
        "            value_dict[label] += 1\n",
        "\n",
        "\n",
        "\n",
        "        print(\"value_dict after statistics: \")\n",
        "        self.distribution = value_dict\n",
        "        print(value_dict)\n",
        "        print(\"-----------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "        if lds:\n",
        "            set_labels_smooth = list(set(labels))\n",
        "            if reweight == 'sqrt_inv':\n",
        "                value_dict = {k: np.sqrt(v) for k, v in value_dict.items()}\n",
        "            elif reweight == 'inverse':\n",
        "                value_dict = {k: np.clip(v, 5, 1000) for k, v in value_dict.items()}  # clip weights for inverse re-weight\n",
        "\n",
        "            num_per_label = [value_dict[label] for label in labels]\n",
        "            if not len(num_per_label) or reweight == 'none':\n",
        "                return None\n",
        "            print(f\"Using re-weighting: [{reweight.upper()}]\")\n",
        "\n",
        "            lds_kernel_window = get_lds_kernel_window(lds_kernel, lds_ks, lds_sigma)\n",
        "            print(f'Using LDS: [{lds_kernel.upper()}] ({lds_ks}/{lds_sigma})')\n",
        "            smoothed_value = convolve1d(\n",
        "                np.asarray([v for _, v in value_dict.items()]), weights=lds_kernel_window, mode='constant')\n",
        "            smoothed_value_dict = {label: smoothed_value[i] for i, label in enumerate(set_labels_smooth)}\n",
        "            num_per_label = [smoothed_value_dict[label] for label in labels]\n",
        "\n",
        "            weights = [np.float32(1 / x) for x in num_per_label]\n",
        "            scaling = len(weights) / np.sum(weights)\n",
        "            weights = [scaling * x for x in weights]\n",
        "            return weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T09:21:29.226350Z",
          "iopub.execute_input": "2023-10-30T09:21:29.226721Z",
          "iopub.status.idle": "2023-10-30T09:21:29.251475Z",
          "shell.execute_reply.started": "2023-10-30T09:21:29.226687Z",
          "shell.execute_reply": "2023-10-30T09:21:29.250248Z"
        },
        "trusted": true,
        "id": "EzSSZe3bPr5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "class NaverDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, batch_size = 128, root_dir = '/content/drive/MyDrive/data/image-rv-70k-round/data70k'):\n",
        "        super().__init__()\n",
        "        self.root_dir = root_dir\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.train_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                                   transforms.Resize((224, 224)),\n",
        "                                                   transforms.RandomHorizontalFlip(p = 0.5),\n",
        "                                                   transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "        self.test_transform = transforms.Compose([# transforms.Resize((384, 288)),\n",
        "                                                  transforms.Resize((224, 224)),\n",
        "                                                  transforms.ToTensor(),\n",
        "                                                  transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None):\n",
        "        if stage == 'fit' or stage is None:\n",
        "            self.train_set = Naver2Dataset(root_dir = self.root_dir, mode = 'train', transform = self.train_transform, lds = False, label_type = 'float')\n",
        "            self.test_set = Naver2Dataset(root_dir = self.root_dir, mode = 'test', transform = self.test_transform,\n",
        "                                          lds = False, label_type = \"float\")\n",
        "\n",
        "\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.test_set = Naver2Dataset(root_dir = self.root_dir, mode = 'test', transform = self.test_transform,\n",
        "                                          lds = False, label_type = \"float\")\n",
        "\n",
        "        if stage == 'predict' or stage is None:\n",
        "            self.predict_set = Naver2Dataset(root_dir = self.root_dir, mode = 'test', transform = self.test_transform,\n",
        "                                             lds = False, label_type = \"float\")\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            dataset  = self.train_set,\n",
        "            batch_size = self.batch_size,\n",
        "            shuffle = True,\n",
        "            num_workers = 12,\n",
        "            persistent_workers = True,\n",
        "            # pin_memory = True\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            dataset = self.test_set,\n",
        "            batch_size = self.batch_size,\n",
        "            num_workers = 12,\n",
        "            persistent_workers = True,\n",
        "            # pin_memory = True,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            dataset = self.test_set,\n",
        "            batch_size = self.batch_size,\n",
        "            num_workers = 12,\n",
        "            persistent_workers = True,\n",
        "            # pin_memory = True,\n",
        "        )\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(\n",
        "            dataset = self.predict_set,\n",
        "            batch_size = self.batch_size,\n",
        "            num_workers = 12,\n",
        "            persistent_workers = True,\n",
        "            # pin_memory = True,\n",
        "        )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-30T09:21:41.287670Z",
          "iopub.execute_input": "2023-10-30T09:21:41.288045Z",
          "iopub.status.idle": "2023-10-30T09:21:41.301800Z",
          "shell.execute_reply.started": "2023-10-30T09:21:41.288012Z",
          "shell.execute_reply": "2023-10-30T09:21:41.300532Z"
        },
        "trusted": true,
        "id": "ktgAJCIyPr5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datamodule = NaverDataModule(root_dir = \"/content/drive/MyDrive/data/image-rv-70k-float/data70k\")\n",
        "# datamodule.setup('test')\n",
        "# test_dataset = datamodule.test_dataloader().dataset"
      ],
      "metadata": {
        "id": "L-bLzakXp71z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SABlock(nn.Module):\n",
        "\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "        self.conv2d = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        avg_pool = torch.mean(inputs, dim=1, keepdim=True)\n",
        "        max_pool, _ = torch.max(inputs, dim=1, keepdim=True)\n",
        "\n",
        "        x = torch.cat([avg_pool, max_pool], dim=1)\n",
        "        x = self.conv2d(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x * inputs\n",
        "\n",
        "class LCABlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.depthwise = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=in_channels,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "            groups=in_channels,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        self.gamma = nn.Parameter(torch.zeros(1, 1, 1, in_channels))\n",
        "        self.beta = nn.Parameter(torch.zeros(1, 1, 1, in_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        group_norm_x = torch.norm(x, p=2, dim=(1, 2), keepdim=True)\n",
        "        relative_important_x = group_norm_x / (group_norm_x.mean(dim=-1, keepdim=True) + 1e-6)\n",
        "        x = self.gamma * (x * relative_important_x) + self.beta + x\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        return x\n",
        "\n",
        "class CABlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super().__init__()\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.block = nn.Sequential(nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
        "                               nn.ReLU(),\n",
        "                               nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False))\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.block(self.avg_pool(x))\n",
        "        max_out = self.block(self.max_pool(x))\n",
        "        out = avg_out + max_out\n",
        "\n",
        "        return self.sigmoid(out) * x"
      ],
      "metadata": {
        "id": "9G23SOLS7nsH",
        "execution": {
          "iopub.status.busy": "2023-10-30T09:22:03.528993Z",
          "iopub.execute_input": "2023-10-30T09:22:03.529872Z",
          "iopub.status.idle": "2023-10-30T09:22:03.544792Z",
          "shell.execute_reply.started": "2023-10-30T09:22:03.529836Z",
          "shell.execute_reply": "2023-10-30T09:22:03.543613Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BackBones"
      ],
      "metadata": {
        "id": "JkGiPqas7qTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ghost Module"
      ],
      "metadata": {
        "id": "ZUEJZa3s7zNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SeperableGhostModule(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        bias=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.primary = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=in_channels,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "                groups=in_channels,\n",
        "                bias=bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels//2,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels//2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.cheap = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=out_channels//2,\n",
        "                out_channels=out_channels//2,\n",
        "                kernel_size=kernel_size,\n",
        "                stride=stride,\n",
        "                padding=kernel_size//2,\n",
        "                groups=out_channels//2,\n",
        "                bias=bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels//2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.primary(x)\n",
        "        x_cheap = self.cheap(x)\n",
        "        x = torch.concat([x, x_cheap], axis=1)\n",
        "        return x\n",
        "\n",
        "class GhostModule(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        bias=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.primary = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels//2,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels//2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.cheap = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=out_channels//2,\n",
        "                out_channels=out_channels//2,\n",
        "                kernel_size=kernel_size,\n",
        "                stride=stride,\n",
        "                padding=kernel_size//2,\n",
        "                groups=out_channels//2,\n",
        "                bias=bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels//2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.primary(x)\n",
        "        x_cheap = self.cheap(x)\n",
        "        x = torch.concat([x, x_cheap], axis=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZF5qgwCF779g",
        "execution": {
          "iopub.status.busy": "2023-10-30T09:22:07.013097Z",
          "iopub.execute_input": "2023-10-30T09:22:07.013476Z",
          "iopub.status.idle": "2023-10-30T09:22:07.027611Z",
          "shell.execute_reply.started": "2023-10-30T09:22:07.013446Z",
          "shell.execute_reply": "2023-10-30T09:22:07.026562Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sperable Block"
      ],
      "metadata": {
        "id": "CF8VKu7C78uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SeperableConv2d(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        padding,\n",
        "        bias=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "RHsiuoQL8BGW",
        "execution": {
          "iopub.status.busy": "2023-10-30T09:22:07.382223Z",
          "iopub.execute_input": "2023-10-30T09:22:07.382578Z",
          "iopub.status.idle": "2023-10-30T09:22:07.388087Z",
          "shell.execute_reply.started": "2023-10-30T09:22:07.382549Z",
          "shell.execute_reply": "2023-10-30T09:22:07.387104Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loss"
      ],
      "metadata": {
        "id": "1dZ0gwDj8C5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RFCLoss(nn.Module):\n",
        "    def __init__(self, alpha=10, min_delta=0.47, loss=nn.L1Loss(reduction = 'none')):\n",
        "        super().__init__()\n",
        "\n",
        "        self.loss = loss\n",
        "        self.alpha = alpha\n",
        "        self.min_delta = min_delta\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        mae_loss = torch.abs(y_pred - y_true)\n",
        "        weights = 1/(1 + torch.exp(self.alpha * (self.min_delta - mae_loss)))\n",
        "        loss = weights * self.loss(y_pred, y_true)\n",
        "\n",
        "        return torch.mean(loss).cuda()"
      ],
      "metadata": {
        "id": "1hLT2bwo8FU9",
        "execution": {
          "iopub.status.busy": "2023-10-30T09:22:08.583929Z",
          "iopub.execute_input": "2023-10-30T09:22:08.584323Z",
          "iopub.status.idle": "2023-10-30T09:22:08.591754Z",
          "shell.execute_reply.started": "2023-10-30T09:22:08.584295Z",
          "shell.execute_reply": "2023-10-30T09:22:08.590759Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DPD Block"
      ],
      "metadata": {
        "id": "A6WdUgdQ8G5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timm.models.layers import DropPath\n",
        "class DPDBlockV1(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        expand_channels,\n",
        "        freeze_channels,\n",
        "        is_downsize=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.expand_channels = self._make_divisible(expand_channels, in_channels)\n",
        "        self.freeze_channels = freeze_channels\n",
        "        self.is_downsize = is_downsize\n",
        "\n",
        "        self.depthwise_expand = nn.Sequential(\n",
        "            SABlock(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.expand_channels,\n",
        "                kernel_size=3,\n",
        "                stride=2 if self.is_downsize else 1,\n",
        "                padding=1,\n",
        "                groups=self.in_channels,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.expand_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pointwise = nn.Sequential(\n",
        "            CABlock(in_channels=self.expand_channels, ratio=8),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.expand_channels,\n",
        "                out_channels=self.freeze_channels,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.freeze_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.depthwise_freeze = nn.Sequential(\n",
        "            SABlock(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.freeze_channels,\n",
        "                out_channels=self.freeze_channels,\n",
        "                kernel_size=3,\n",
        "                stride=2 if self.is_downsize else 1,\n",
        "                padding=1,\n",
        "                groups=self.freeze_channels,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.freeze_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.skip_att = SABlock()\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        inputs = x\n",
        "        x = self.depthwise_expand(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.depthwise_freeze(x)\n",
        "\n",
        "        if not(self.is_downsize) and x.shape == inputs.shape:\n",
        "            inputs = self.skip_att(inputs)\n",
        "            x = inputs + x\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_divisible(self, out_channels, groups):\n",
        "        ratio = out_channels // groups\n",
        "        return int(groups * ratio)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "class DPDBlockV3(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        expand_channels,\n",
        "        freeze_channels,\n",
        "        is_downsize=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.expand_channels = self._make_divisible(expand_channels, in_channels)\n",
        "        self.freeze_channels = freeze_channels\n",
        "        self.is_downsize = is_downsize\n",
        "\n",
        "        self.depthwise_expand = nn.Sequential(\n",
        "            SABlock(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.expand_channels,\n",
        "                kernel_size=3,\n",
        "                stride=2 if self.is_downsize else 1,\n",
        "                padding=1,\n",
        "                groups=self.in_channels,\n",
        "                bias=True\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.expand_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pointwise = nn.Sequential(\n",
        "            LCABlock(in_channels=self.expand_channels),\n",
        "            SeperableGhostModule(\n",
        "                in_channels=self.expand_channels,\n",
        "                out_channels=self.freeze_channels,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=True\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.depthwise_freeze = nn.Sequential(\n",
        "            SABlock(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.freeze_channels,\n",
        "                out_channels=self.freeze_channels,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "                groups=self.freeze_channels,\n",
        "                bias=True\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.freeze_channels),\n",
        "        )\n",
        "\n",
        "        self.drop_path = DropPath(0.2)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        inputs = x\n",
        "        x = self.depthwise_expand(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.depthwise_freeze(x)\n",
        "\n",
        "        if not(self.is_downsize) and x.shape == inputs.shape:\n",
        "            x = x + self.drop_path(inputs)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_divisible(self, out_channels, groups):\n",
        "        ratio = out_channels // groups\n",
        "        return int(groups * ratio)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "class DPDBlockV2(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        expand_channels,\n",
        "        freeze_channels,\n",
        "        is_downsize=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.expand_channels = self._make_divisible(expand_channels, in_channels)\n",
        "        self.freeze_channels = freeze_channels\n",
        "        self.is_downsize = is_downsize\n",
        "\n",
        "        self.depthwise_expand = nn.Sequential(\n",
        "            SABlock(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.expand_channels,\n",
        "                kernel_size=3,\n",
        "                stride=2 if self.is_downsize else 1,\n",
        "                padding=1,\n",
        "                groups=self.in_channels,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.expand_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pointwise = nn.Sequential(\n",
        "            LCABlock(in_channels=self.expand_channels),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.expand_channels,\n",
        "                out_channels=self.freeze_channels,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.freeze_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.depthwise_freeze = nn.Sequential(\n",
        "            SABlock(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.freeze_channels,\n",
        "                out_channels=self.freeze_channels,\n",
        "                kernel_size=3,\n",
        "                stride=2 if self.is_downsize else 1,\n",
        "                padding=1,\n",
        "                groups=self.freeze_channels,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.freeze_channels),\n",
        "        )\n",
        "\n",
        "        self.drop_path = DropPath(0.2)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        inputs = x\n",
        "        x = self.depthwise_expand(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.depthwise_freeze(x)\n",
        "\n",
        "        if not(self.is_downsize) and x.shape == inputs.shape:\n",
        "            x = x + self.drop_path(inputs)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_divisible(self, out_channels, groups):\n",
        "        ratio = out_channels // groups\n",
        "        return int(groups * ratio)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)"
      ],
      "metadata": {
        "id": "oxnEux5W8K0A",
        "execution": {
          "iopub.status.busy": "2023-10-30T09:22:09.850732Z",
          "iopub.execute_input": "2023-10-30T09:22:09.851103Z",
          "iopub.status.idle": "2023-10-30T09:22:09.890436Z",
          "shell.execute_reply.started": "2023-10-30T09:22:09.851070Z",
          "shell.execute_reply": "2023-10-30T09:22:09.889461Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationFunction(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.name = self.__class__.__name__\n",
        "        self.config = {\"name\": self.name}\n",
        "class ReLU_04(ActivationFunction):\n",
        "    def forward(self, x):\n",
        "        x = x * (x > 0).float()\n",
        "        # * (x > 0) if true, return 1, therefore x * 1 = x, x <= 0 true then x > 0 = 1 then it is 0\n",
        "        # If x >=4 then (x >= 4) = 1 and (x < 4) = 0; then it choose one of x or 4\n",
        "        return ((x >= 4) * 4 + (x < 4) * x).float()"
      ],
      "metadata": {
        "id": "pc0SUN1TKP2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PL_Trainer"
      ],
      "metadata": {
        "id": "jCO_oUWE8MA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DMGNet(pl.LightningModule):\n",
        "    def __init__(self, lds = True):\n",
        "        super().__init__()\n",
        "        self.lds = lds\n",
        "        self.configure_criterion()\n",
        "        self.backbone = BackboneFactory.create_model(\"mobile_torchvision_13\")\n",
        "#         for param in self.backbone.parameters():\n",
        "#             param.require_grad = False\n",
        "\n",
        "#         for module in self.backbone.modules():\n",
        "#             if isinstance(module, nn.BatchNorm2d):\n",
        "#                 if hasattr(module, 'weight'):\n",
        "#                     module.weight.requires_grad_(False)\n",
        "#                 if hasattr(module, 'bias'):\n",
        "#                     module.bias.requires_grad_(False)\n",
        "# #                 module.affine = False\n",
        "#                 module.eval()\n",
        "\n",
        "        self.init_conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=576,\n",
        "                out_channels=64,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "\n",
        "        self.dpd_blocks = nn.Sequential(\n",
        "            DPDBlockV3(64, 384, 96, False),\n",
        "            DPDBlockV3(96, 576, 160, True),\n",
        "            DPDBlockV3(160, 960, 160, False),\n",
        "            DPDBlockV3(160, 960, 320, False)\n",
        "        )\n",
        "\n",
        "        self.smooth_conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=320,\n",
        "                out_channels=256,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.loss_fn = RFCLoss()\n",
        "        self.test_metric = torch.nn.L1Loss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = x[\"expand\"]\n",
        "        x = self.init_conv(x)\n",
        "        x = self.dpd_blocks(x)\n",
        "        x = self.smooth_conv(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def configure_criterion(self):\n",
        "        if self.lds:\n",
        "            def weighted_mse_loss(inputs, targets, weights=None):\n",
        "                loss = (inputs - targets) ** 2\n",
        "                if weights is not None:\n",
        "                    loss *= weights.expand_as(loss)\n",
        "                loss = torch.mean(loss)\n",
        "                return loss\n",
        "            self.train_criterion = weighted_mse_loss # nn.L1Loss()\n",
        "        else:\n",
        "            self.train_criterion = nn.L1Loss()\n",
        "        self.test_criterion = nn.L1Loss()\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=8, min_lr=1e-7, verbose=True)\n",
        "\n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        if self.lds:\n",
        "            x, y, weights = batch\n",
        "            yhat = self.forward(x)\n",
        "            train_loss = self.train_criterion(yhat, y, weights)\n",
        "        else:\n",
        "            x, y = batch\n",
        "            yhat = self.forward(x)\n",
        "            train_loss = self.train_criterion(yhat, y)\n",
        "        # y = y.squeeze(dim = 1)\n",
        "\n",
        "        self.log(\"train_loss\", train_loss)\n",
        "        # self.log(\"train_loss\", train_loss, on_step=False, on_epoch=True, prog_bar=True, sync_dist = True)\n",
        "        # self.lr_scheduler.step()\n",
        "        # self.log(\"lr\", round(self.lr_scheduler.get_lr()[0], 5), prog_bar=True, logger=True, on_step=True)\n",
        "        return train_loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y, _ = batch\n",
        "        # y = y.squeeze(dim = 1)\n",
        "\n",
        "        yhat = self.forward(x)\n",
        "        val_loss = self.test_criterion(yhat, y)\n",
        "        # self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=True, sync_dist = True)\n",
        "\n",
        "        # self.log(\"lr\", round(self.lr_schduler.get_lr()[0], 5), prog_bar=True, logger=True, on_step=True)\n",
        "\n",
        "        self.log(\"val_loss\", val_loss)\n",
        "        return val_loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y,_ = batch\n",
        "        # y = y.squeeze(dim = 1)\n",
        "        yhat = self.forward(x)\n",
        "        mae_loss = nn.L1Loss()(yhat, y)\n",
        "        test_loss = mae_loss\n",
        "        self.log_dict(dictionary = test_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return test_loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        x,y, _ = batch\n",
        "        yhat = ReLU_04()(self(x))\n",
        "\n",
        "        # yhat = torch.argmax(self(x))\n",
        "        return yhat\n"
      ],
      "metadata": {
        "id": "wyd64SD58R4W",
        "execution": {
          "iopub.status.busy": "2023-10-30T09:22:10.904482Z",
          "iopub.execute_input": "2023-10-30T09:22:10.905377Z",
          "iopub.status.idle": "2023-10-30T09:22:10.928906Z",
          "shell.execute_reply.started": "2023-10-30T09:22:10.905343Z",
          "shell.execute_reply": "2023-10-30T09:22:10.927786Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchvision.models.ShuffleNetV2"
      ],
      "metadata": {
        "id": "Sfy0vVRLTwyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ShuffleNet"
      ],
      "metadata": {
        "id": "jUplZJJ9prre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "# from modules.backbone import BackboneFactory\n",
        "# from modules.dpd_blocks import DPDBlockV1, DPDBlockV2, DPDBlockV3\n",
        "# from modules.losses import RFCLoss\n",
        "# from modules.mobiledpd_version import MobileDPD10, MobileDPD13, MobileDPDBig\n",
        "import torchvision\n",
        "from torchmetrics import F1Score, Accuracy\n",
        "\n",
        "class InferenceModel(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.focal_loss = torch.nn.CrossEntropyLoss(torch.tensor([50., 9., 3., 1.88, 50.]).to(\"cuda:1\"))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "\n",
        "# class MobileNet(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.backbone = BackboneFactory.create_model(\"mobilenet\")\n",
        "\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.backbone(x)\n",
        "#         return x\n",
        "\n",
        "# class QualityNet(pl.LightningModule):\n",
        "#     def __init__(self, model=MobileNet()):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.model = model\n",
        "\n",
        "#         self.focal_loss = torch.nn.CrossEntropyLoss(torch.tensor([50., 9., 3., 1.88, 50.]).to(\"cuda:1\"))\n",
        "#         self.f1_train = F1Score(task=\"multiclass\", num_classes=5, average=\"macro\")\n",
        "#         self.f1_val = F1Score(task=\"multiclass\", num_classes=5, average=\"macro\")\n",
        "#         self.acc_train = Accuracy(task=\"multiclass\", num_classes=5)\n",
        "#         self.acc_val = Accuracy(task=\"multiclass\", num_classes=5)\n",
        "#         self.validation_step_outputs = []\n",
        "\n",
        "#     def forward(self, x, label):\n",
        "#         x = self.model(x)\n",
        "#         return x\n",
        "\n",
        "#     def configure_optimizers(self):\n",
        "#         optimizer = torch.optim.Adam(self.parameters(), lr=2e-5)\n",
        "#         # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0)\n",
        "#         scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=7, min_lr=1e-7, verbose=True)\n",
        "\n",
        "#         return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_acc\"}\n",
        "\n",
        "#     def _calculate_train_acc(self, batch):\n",
        "#         images, labels = batch\n",
        "\n",
        "#         logits = self.forward(images, labels)\n",
        "#         preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "#         f1 = self.f1_train(preds, labels)\n",
        "#         acc = self.acc_train(labels, preds)\n",
        "\n",
        "#         return acc, f1\n",
        "\n",
        "#     def _calculate_val_acc(self, batch):\n",
        "#         images, labels = batch\n",
        "\n",
        "#         logits = self.forward(images, labels)\n",
        "#         preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "#         self.f1_val.update(preds, labels)\n",
        "#         self.acc_val.update(labels, preds)\n",
        "\n",
        "#     def _calculate_loss(self, batch):\n",
        "#         image, label = batch\n",
        "#         y_pred = self.forward(image, label)\n",
        "\n",
        "#         loss = self.focal_loss(y_pred, label)\n",
        "#         return loss\n",
        "\n",
        "#     def _calculate_test_loss(self, batch):\n",
        "#         image, label = batch\n",
        "#         y_pred = self.forward(image, label)\n",
        "\n",
        "#         loss = self.focal_loss(y_pred, label)\n",
        "#         return loss, y_pred\n",
        "\n",
        "#     def training_step(self, batch, batch_index):\n",
        "#         image, label = batch\n",
        "#         loss, y_pred = self._calculate_test_loss(batch)\n",
        "#         acc, f1 = self._calculate_train_acc(batch)\n",
        "\n",
        "#         self.log(\"train_loss\", loss, prog_bar=True)\n",
        "#         self.log(\"train_f1\", f1, prog_bar=True)\n",
        "#         self.log(\"train_acc\", acc, prog_bar=True)\n",
        "\n",
        "#         return {\"loss\": loss, \"predictions\": y_pred, \"labels\": label}\n",
        "\n",
        "#     def on_train_epoch_end(self):\n",
        "#         # compute metrics\n",
        "#         train_accuracy = self.acc_train.compute()\n",
        "#         train_f1 = self.f1_train.compute()\n",
        "#         # log metrics\n",
        "#         self.log(\"epoch_train_accuracy\", train_accuracy)\n",
        "#         self.log(\"epoch_train_f1\", train_f1)\n",
        "#         # reset all metrics\n",
        "#         self.acc_train.reset()\n",
        "#         self.f1_train.reset()\n",
        "#         print(f\"\\ntraining accuracy: {train_accuracy:.4}, \"\\\n",
        "#         f\"f1: {train_f1:.4}\")\n",
        "\n",
        "# #         preds = []\n",
        "# #         labels = []\n",
        "\n",
        "# #         for output in training_step_outputs:\n",
        "# #             logits = output['predictions']\n",
        "# #             preds += torch.argmax(logits, dim=-1).cpu().numpy().tolist()\n",
        "# #             labels += output['labels'].cpu().numpy().tolist()\n",
        "\n",
        "#         # print(classification_report(labels, preds))\n",
        "\n",
        "#     def validation_step(self, batch, batch_index):\n",
        "#         image, label = batch\n",
        "#         loss, y_pred = self._calculate_test_loss(batch)\n",
        "#         self._calculate_val_acc(batch)\n",
        "\n",
        "#         self.log(\"val_loss\", loss)\n",
        "\n",
        "#         return {\"val_loss\": loss, \"predictions\": y_pred, \"labels\": label}\n",
        "\n",
        "#     # Validation epoch end\n",
        "#     def on_validation_epoch_end(self):\n",
        "#         val_accuracy = self.acc_val.compute()\n",
        "#         val_f1 = self.f1_val.compute()\n",
        "#         # log metrics\n",
        "#         self.log(\"val_acc\", val_accuracy)\n",
        "#         self.log(\"val_f1\", val_f1)\n",
        "#         # reset all metrics\n",
        "#         self.acc_val.reset()\n",
        "#         self.f1_val.reset()\n",
        "#         print(f\"\\nValidation accuracy: {val_accuracy:.4} \"\\\n",
        "#         f\"f1: {val_f1:.4}\")\n",
        "\n",
        "# #         preds = []\n",
        "# #         labels = []\n",
        "\n",
        "# #         for output in self.validation_step_outputs:\n",
        "# #             logits = output['predictions']\n",
        "# #             preds += torch.argmax(logits, dim=-1).cpu().numpy().tolist()\n",
        "# #             labels += output['labels'].cpu().numpy().tolist()\n",
        "\n",
        "# #         print(classification_report(labels, preds))\n",
        "\n",
        "#     def test_step(self, batch, batch_index):\n",
        "#         loss = self._calculate_loss(batch)\n",
        "#         self._calculate_val_acc(batch)\n",
        "\n",
        "#         # self.log(\"test_loss\", loss)\n",
        "\n",
        "#         return loss\n",
        "\n",
        "#     def on_test_epoch_end(self):\n",
        "#         val_accuracy = self.acc_val.compute()\n",
        "#         val_f1 = self.f1_val.compute()\n",
        "#         # log metrics\n",
        "#         self.log(\"val_acc\", val_accuracy)\n",
        "#         self.log(\"val_f1\", val_f1)\n",
        "#         # reset all metrics\n",
        "#         self.acc_val.reset()\n",
        "#         self.f1_val.reset()\n",
        "#         print(f\"\\nTest accuracy: {val_accuracy:.4} \"\\\n",
        "#         f\"Test f1: {val_f1:.4}\")\n",
        "\n",
        "class ShuffleNet(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "#         # ShuffleNet\n",
        "        # self.backbone = BackboneFactory.create_model(\"shufflenet\")\n",
        "\n",
        "#         GhostNet\n",
        "#         self.backbone = BackboneFactory.create_model(\"ghost\")\n",
        "#         self.backbone.classifier = nn.Sequential(\n",
        "#             nn.Linear(1280, 1)\n",
        "\n",
        "#         )\n",
        "        #MobileNetV3\n",
        "        # self.backbone = BackboneFactory.create_model(\"mobilev3\")\n",
        "#         MobileNetV2\n",
        "        self.backbone = BackboneFactory.create_model(\"mobilenet\")\n",
        "\n",
        "        # MobileDPD10\n",
        "#         self.backbone = MobileDPD10()\n",
        "\n",
        "        # MobileDPD13\n",
        "#         self.backbone = MobileDPD13()\n",
        "        # MobileDPDBig\n",
        "#         self.backbone = MobileDPDBig()\n",
        "\n",
        "        self.loss_fn = torch.nn.L1Loss()\n",
        "        self.test_metric = torch.nn.L1Loss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "#         x = x[\"expand\"]\n",
        "#         x = self.init_conv(x)\n",
        "#         x = self.dpd_blocks(x)\n",
        "#         x = self.smooth_conv(x)\n",
        "#         x = self.gap(x)\n",
        "#         x = self.classifier(x)\n",
        "#         x = torch.where(x > 4, 4, x)\n",
        "#         x = torch.where(x < 0, 0, x)\n",
        "\n",
        "        return x * 4\n",
        "\n",
        "    def get_top_layers(self):\n",
        "        return nn.Sequential(\n",
        "            self.dpd_blocks,\n",
        "            self.smooth_conv,\n",
        "            self.gap,\n",
        "            self.classifier\n",
        "        )\n",
        "\n",
        "#     def get_backbone(self):\n",
        "#         return nn.Sequential(\n",
        "#             self.backbone,\n",
        "#             self.init_conv\n",
        "#         )\n",
        "    def get_backbone_feature(self, x):\n",
        "        self.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            x = self.backbone(x)\n",
        "            x = x[\"expand\"]\n",
        "            x = self.init_conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=7, min_lr=1e-7, verbose=True)\n",
        "\n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
        "\n",
        "    def _calculate_loss(self, batch):\n",
        "        image, rating = batch\n",
        "        y_pred = self.forward(image)\n",
        "        y_pred = y_pred[:, 0]\n",
        "\n",
        "        loss = self.loss_fn(y_pred, rating)\n",
        "        return loss\n",
        "\n",
        "    def _calculate_test_loss(self, batch):\n",
        "        image, rating = batch\n",
        "        y_pred = self.forward(image)\n",
        "        y_pred = y_pred[:, 0]\n",
        "\n",
        "        loss = self.test_metric(y_pred, rating)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        loss = self._calculate_loss(batch)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_index):\n",
        "        loss = self._calculate_test_loss(batch)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "        return {\"val_loss\": loss}\n",
        "\n",
        "    def test_step(self, batch, batch_index):\n",
        "        loss = self._calculate_test_loss(batch)\n",
        "\n",
        "        self.log(\"test_loss\", loss)\n",
        "\n",
        "        return loss\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        x,y= batch\n",
        "        yhat = ReLU_04()(self(x))\n",
        "\n",
        "        # yhat = torch.argmax(self(x))\n",
        "        return yhat\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BgXaKFYvpyG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "torchvision.models.mobilenet_v3_small"
      ],
      "metadata": {
        "id": "0st34b7fP-lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Net_Trainer"
      ],
      "metadata": {
        "id": "srhIj9kT8SO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import pytorch_lightning as pl\n",
        "# from modules.backbone import BackboneFactory\n",
        "# from modules.dpd_blocks import DPDBlockV1, DPDBlockV2, DPDBlockV3\n",
        "\n",
        "class ScratchNet(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "#         self.backbone = BackboneFactory.create_model(\"mobile_torchvision_13\")\n",
        "# #         for param in self.backbone.parameters():\n",
        "# #             param.require_grad = False\n",
        "\n",
        "#         for module in self.backbone.modules():\n",
        "#             if isinstance(module, nn.BatchNorm2d):\n",
        "#                 if hasattr(module, 'weight'):\n",
        "#                     module.weight.requires_grad_(False)\n",
        "#                 if hasattr(module, 'bias'):\n",
        "#                     module.bias.requires_grad_(False)\n",
        "# #                 module.affine = False\n",
        "#                 module.eval()\n",
        "\n",
        "        self.init_conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=3,\n",
        "                out_channels=32,\n",
        "                kernel_size=3,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.sep_block = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=32,\n",
        "                out_channels=32,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "                groups=32,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                in_channels=32,\n",
        "                out_channels=16,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(16),\n",
        "        )\n",
        "\n",
        "        self.dpd_blocks = nn.Sequential(\n",
        "            DPDBlockV3(16, 96, 16, False),\n",
        "            DPDBlockV3(16, 96, 24, True),\n",
        "            nn.Dropout(0.2),\n",
        "            DPDBlockV3(24, 144, 24, False),\n",
        "            DPDBlockV3(24, 144, 32, True),\n",
        "            nn.Dropout(0.2),\n",
        "            DPDBlockV3(32, 192, 32, False),\n",
        "            DPDBlockV3(32, 192, 48, True),\n",
        "            nn.Dropout(0.2),\n",
        "            DPDBlockV3(48, 288, 48, False),\n",
        "            DPDBlockV3(48, 288, 64, True),\n",
        "            nn.Dropout(0.2),\n",
        "            DPDBlockV3(64, 256, 64, False),\n",
        "            DPDBlockV3(64, 256, 64, False),\n",
        "            DPDBlockV3(64, 256, 96, False)\n",
        "        )\n",
        "\n",
        "        self.smooth_conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=96,\n",
        "                out_channels=256,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=True\n",
        "            ),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.loss_fn = torch.nn.L1Loss()\n",
        "        self.test_metric = torch.nn.L1Loss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.init_conv(x)\n",
        "        x = self.sep_block(x)\n",
        "        x = self.dpd_blocks(x)\n",
        "        x = self.smooth_conv(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=0.001, weight_decay=0.0001, eps=1e-08)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.2, patience=5, min_lr=1e-7, verbose=True)\n",
        "\n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
        "\n",
        "    def _calculate_loss(self, batch):\n",
        "        image, rating = batch\n",
        "        y_pred = self.forward(image)\n",
        "        y_pred = y_pred[:, 0]\n",
        "\n",
        "        loss = self.loss_fn(y_pred, rating)\n",
        "        return loss\n",
        "\n",
        "    def _calculate_test_loss(self, batch):\n",
        "        image, rating = batch\n",
        "        y_pred = self.forward(image)\n",
        "        y_pred = y_pred[:, 0]\n",
        "\n",
        "        loss = self.test_metric(y_pred, rating)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        loss = self._calculate_loss(batch)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_index):\n",
        "        loss = self._calculate_test_loss(batch)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "        return {\"val_loss\": loss}\n",
        "\n",
        "    def test_step(self, batch, batch_index):\n",
        "        loss = self._calculate_test_loss(batch)\n",
        "\n",
        "        self.log(\"test_loss\", loss)\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "P3g0jDPk8WpS",
        "execution": {
          "iopub.status.busy": "2023-10-30T09:22:13.846003Z",
          "iopub.execute_input": "2023-10-30T09:22:13.846620Z",
          "iopub.status.idle": "2023-10-30T09:22:13.875647Z",
          "shell.execute_reply.started": "2023-10-30T09:22:13.846579Z",
          "shell.execute_reply": "2023-10-30T09:22:13.874713Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NCfuuUbkB0La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "ecTTQ_VB8j5z",
        "execution": {
          "iopub.status.busy": "2023-10-30T09:22:25.907729Z",
          "iopub.execute_input": "2023-10-30T09:22:25.908190Z",
          "iopub.status.idle": "2023-10-30T09:22:25.916140Z",
          "shell.execute_reply.started": "2023-10-30T09:22:25.908149Z",
          "shell.execute_reply": "2023-10-30T09:22:25.915258Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key=\"a851146869476d016286e78f75911117e3701e5c\")"
      ],
      "metadata": {
        "id": "d7rXa6b68bE6",
        "execution": {
          "iopub.status.busy": "2023-10-30T09:22:25.917406Z",
          "iopub.execute_input": "2023-10-30T09:22:25.917673Z",
          "iopub.status.idle": "2023-10-30T09:22:29.011266Z",
          "shell.execute_reply.started": "2023-10-30T09:22:25.917649Z",
          "shell.execute_reply": "2023-10-30T09:22:29.010342Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "id": "yBV4MlQX8fql",
        "execution": {
          "iopub.status.busy": "2023-10-30T09:22:29.012978Z",
          "iopub.execute_input": "2023-10-30T09:22:29.013602Z",
          "iopub.status.idle": "2023-10-30T09:22:29.019762Z",
          "shell.execute_reply.started": "2023-10-30T09:22:29.013560Z",
          "shell.execute_reply": "2023-10-30T09:22:29.018818Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.serialization import MAP_LOCATION\n",
        "from lightning_fabric.accelerators import accelerator\n",
        "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoin\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# DataModule\n",
        "# review_datamodule = ReviewDataModule(train_csv,test_new_csv, batch_size=64)\n",
        "datamodule = NaverDataModule(\n",
        "    root_dir = '/content/drive/MyDrive/data/image-rv-70k-float/data70k',\n",
        "    batch_size = 128)\n",
        "\n",
        "# Checkpoint\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "        dirpath=\"/content/drive/MyDrive/Data_Naver_ImageReview/weights/best_model_shuffle\",\n",
        "        filename='dmg_net_v3_{epoch}_{val_loss:.3f}',\n",
        "        save_top_k=1,\n",
        "        verbose=True,\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        ")\n",
        "\n",
        "# Training\n",
        "# wandb_logger = WandbLogger(project=\"imagereview\", log_model=\"all\")\n",
        "# wandb_logger.experiment.config[\"batch_size\"] = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = ShuffleNet()\n",
        "# model = torch.load(\"/content/drive/MyDrive/Data_Naver_ImageReview/weights/best_model/dmg_net_v3_epoch=28_val_loss=0.492.ckpt\", map_location=device)\n",
        "model =DMGNet.load_from_checkpoint(\"\", map_location=device)\n",
        "\n",
        "trainer = pl.Trainer(accelerator=\"gpu\",\n",
        "                     devices=[0],\n",
        "                     max_epochs=100,\n",
        "                     callbacks=[checkpoint_callback], accumulate_grad_batches=2)\n",
        "\n",
        "trainer.fit(model, datamodule)\n"
      ],
      "metadata": {
        "id": "7IoZFpW48naa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VALIDATE"
      ],
      "metadata": {
        "id": "y6weiTdi0NPU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MVbT64N7YSKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def mae_cus(A, B, l_range):\n",
        "    loss = 0\n",
        "    count = 0\n",
        "    for i in range(len(A)):\n",
        "        if l_range[0] <= B[i] <= l_range[1]:\n",
        "            loss += abs(A[i] - B[i])\n",
        "            count += 1\n",
        "    if count == 0:\n",
        "        return 'No predicted label at {}'.format(values)\n",
        "    cost = loss/count\n",
        "    return round(cost.item(), 4)\n",
        "\n",
        "def predict(ckpt_name):\n",
        "    # global trainer\n",
        "    model =DMGNet.load_from_checkpoint(\"/content/drive/MyDrive/Data_Naver_ImageReview/weights/best_model/\" + ckpt_name, map_location=device)\n",
        "    predictions = trainer.predict(model = model, datamodule = val_dataloader, return_predictions = True)\n",
        "    y_pred = [y for batch in predictions for y in batch]\n",
        "    return y_pred\n",
        "\n",
        "def evaluate(ckpt_name):\n",
        "    print(\"Evaluation for {}: \".format(ckpt_name))\n",
        "    global y_real\n",
        "    y_pred = predict(ckpt_name)\n",
        "    print(\"Total mae: \", mae_cus(y_pred, y_real, l_range = [0, 4]))\n",
        "    # print(\"Total mse: \", mse_cus(y_pred, y_real, [0, 4]))\n",
        "    print(\"MAE for 3: \", mae_cus(y_pred, y_real, [2.5, 3.5]))\n",
        "    print(\"MSE for 4: \", mae_cus(y_pred, y_real, [3.5, 4]))\n",
        "    print(\"MAE for 3, 4: \", mae_cus(y_pred, y_real, [2.5, 4]))"
      ],
      "metadata": {
        "id": "do9hxNT9hyNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\"dmg_net_v3_epoch=7_val_loss=0.394.ckpt\")\n",
        "model = torch.vison"
      ],
      "metadata": {
        "id": "hAGaKQDTo-ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "HoRZM-LFjfdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datamodule = NaverDataModule(root_dir = \"/content/drive/MyDrive/Data_NAVER_Image_Review/image-rv-70k-float/data70k\")\n",
        "datamodule.setup('test')\n",
        "test_dist = datamodule.test_dataloader().dataset.distribution\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_yscale('log')\n",
        "plt.bar(test_dist.keys(), test_dist.values())\n"
      ],
      "metadata": {
        "id": "s3eqGb2pDsLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_y_real(label_type = \"float\"):\n",
        "    y_real = Naver2Dataset('/content/drive/MyDrive/Data_NAVER_Image_Review/image-rv-70k-float/data70k', mode = 'test', lds = False, label_type=\"float\").labels\n",
        "    if label_type == \"int\":\n",
        "        y_real = [round(label) for label in y_real]\n",
        "    return y_real\n",
        "y_real = get_y_real()"
      ],
      "metadata": {
        "id": "NySW2OMFG-GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mae_cus(y_pred, y_real, l_range, type_metrics = 'prec'):\n",
        "    loss = 0\n",
        "    count = 0\n",
        "    for i in range(len(y_pred)):\n",
        "        if l_range[0] <= y_real[i] <= l_range[1]:\n",
        "            loss += abs(y_pred[i] - y_real[i])\n",
        "            count += 1\n",
        "    if count == 0:\n",
        "        return 'No predicted label at {}'.format([y_real, l_range])\n",
        "\n",
        "    if type_metrics == 'prec':\n",
        "        loss = loss/count\n",
        "    return round(loss.item(), 4)\n",
        "\n",
        "def mse_cus(y_pred, y_real, l_range, type_metrics = 'prec'):\n",
        "    loss = 0\n",
        "    count = 0\n",
        "    for i in range(len(y_pred)):\n",
        "        if l_range[0] <= y_real[i] <= l_range[1]:\n",
        "            loss += (y_pred[i] - y_real[i])**2\n",
        "            count += 1\n",
        "    if count == 0:\n",
        "        return 'No predicted label at {}'.format([y_real, l_range])\n",
        "    if type_metrics == 'prec':\n",
        "        loss = loss/count\n",
        "\n",
        "    return round(loss.item(), 4)\n",
        "\n",
        "def predict(ckpt_name):\n",
        "    global trainer\n",
        "    model = ShuffleNet.load_from_checkpoint(\"/content/drive/MyDrive/Data_NAVER_Image_Review/weights/best_model/\" + ckpt_name)\n",
        "    # print(\"batch_size: \", model.batch_size)\n",
        "    predictions = trainer.predict(model = model, datamodule = datamodule, return_predictions = True)\n",
        "    y_pred = [y for batch in predictions for y in batch]\n",
        "    return y_pred\n",
        "\n",
        "def scatter_plot(y_pred, y_real):\n",
        "    data = {'predict': y_pred, 'real': y_real}\n",
        "    plt.scatter(y = 'predict', x = 'real', data = data)\n",
        "    plt.xlabel('real')\n",
        "    plt.ylabel('predict')\n",
        "    plt.figure()\n",
        "\n",
        "def combine_list_to_df(y_pred, y_real):\n",
        "    if torch.is_tensor(y_pred[0]):\n",
        "        y_pred_ = [e.item() for e in y_pred]\n",
        "    else:\n",
        "        y_pred_ = y_pred\n",
        "\n",
        "    if torch.is_tensor(y_real[0]):\n",
        "        y_real_ = [e.item() for e in y_real]\n",
        "    else:\n",
        "        y_real_ = y_real\n",
        "\n",
        "\n",
        "    data = {'predict': y_pred_, 'real': y_real_}\n",
        "    inferred_df = pd.DataFrame(data = data)\n",
        "    return inferred_df\n",
        "\n",
        "def cal_linearity(inferred_df):\n",
        "    display(inferred_df.corr(method = 'pearson'))\n",
        "    display(inferred_df.corr(method = 'spearman'))\n",
        "\n",
        "def hist_plot_dist_by(inferred_df, l_range, ckpt_name):\n",
        "    df_label = inferred_df.loc[(inferred_df['real'] >= l_range[0]) & (inferred_df['real'] <= l_range[1])]\n",
        "    # print(df_label)\n",
        "    sns.histplot(x = df_label['predict'], bins = 20)\\\n",
        "        .set(title= 'Hist plot for label = {} of {}'.format(str(l_range), ckpt_name))\n",
        "    plt.show(block = False)\n",
        "\n",
        "\n",
        "def evaluate(ckpt_name, mode = 'regress'):\n",
        "    print(\"Evaluation for {}: \".format(ckpt_name))\n",
        "    global y_real\n",
        "    y_pred = predict(ckpt_name)\n",
        "    print(\"Total mae: \", mae_cus(y_pred, y_real, l_range = [0, 4]))\n",
        "    print(\"Total mse: \", mse_cus(y_pred, y_real, [0, 4]))\n",
        "    print(\"MAE for 3: \", mae_cus(y_pred, y_real, [2.5, 3.5]))\n",
        "    print(\"MAE for 4: \", mae_cus(y_pred, y_real, [3.5, 4]))\n",
        "    print(\"MAE for 3, 4: \", mae_cus(y_pred, y_real, [2.5, 4]))\n",
        "\n",
        "\n",
        "    if mode == 'classify':\n",
        "        print(\"Confusion matrix: \")\n",
        "        coff_mat = ConfusionMatrix(task = 'multiclass', num_classes = 5)\n",
        "        print(coff_mat(torch.Tensor(y_pred), torch.Tensor(y_real)))\n",
        "\n",
        "    inferred_df = combine_list_to_df(y_pred, y_real)\n",
        "    print(\"Calculate linearity: \")\n",
        "    cal_linearity(inferred_df)\n",
        "\n",
        "\n",
        "    print(\"Hist plot for table: \")\n",
        "    mae_each_label = {}\n",
        "    for i in range(5):\n",
        "        hist_plot_dist_by(inferred_df, l_range = [i - 0.5, i + 0.5], ckpt_name = ckpt_name)\n",
        "\n",
        "    for i in range(len(y_pred)):\n",
        "        mae_each_label[y_real[i]] = mae_each_label.get(y_real[i], 0) + abs(y_pred[i] - y_real[i]).item()\n",
        "\n",
        "    for key, value in mae_each_label.items():\n",
        "        mae_each_label[key] = value/test_dist[key]\n",
        "\n",
        "    # _ , ax = plt.subplots()\n",
        "    # ax.set_title('Test loss for each label of {}'.format(ckpt_name))\n",
        "    sns.barplot(x = list(mae_each_label.keys()), y = list(mae_each_label.values())).set(title = 'Test loss for each label of {}'.format(ckpt_name))\n",
        "    plt.show(block = False)\n",
        "\n",
        "    # test_dist_df = combine_list_to_df(list(test_dist.values()), list(mae_each_label.values()))\n",
        "    # cal_linearity(test_dist_df)\n",
        "\n",
        "    print(\"Loss \")\n",
        "    sns.boxplot(x = 'real', y = 'predict', data = inferred_df)\\\n",
        "        .set(title= 'Total box plot of {}'.format(ckpt_name))\n",
        "    plt.show(block = False)\n",
        "    sns.violinplot(x = 'real', y = 'predict', data = inferred_df)\\\n",
        "        .set(title= 'Total violin plot of {}'.format(ckpt_name))\n",
        "    plt.show(block = False)\n",
        "\n",
        "    print(\"Max value of predictions: {}\".format(max(y_pred)))"
      ],
      "metadata": {
        "id": "bPULm6g4Dw8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\"dmg_net_v3_epoch=4_val_loss=0.568.ckpt\")\n"
      ],
      "metadata": {
        "id": "HHQot_eKD3et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "def _plot_series(series, series_name, series_index=0):\n",
        "  from matplotlib import pyplot as plt\n",
        "  import seaborn as sns\n",
        "  palette = list(sns.palettes.mpl_palette('Dark2'))\n",
        "  xs = series['real']\n",
        "  ys = series['predict']\n",
        "\n",
        "  plt.plot(xs, ys, label=series_name, color=palette[series_index % len(palette)])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')\n",
        "df_sorted = _df_3.sort_values('real', ascending=True)\n",
        "_plot_series(df_sorted, '')\n",
        "sns.despine(fig=fig, ax=ax)\n",
        "plt.xlabel('real')\n",
        "_ = plt.ylabel('predict')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "YrheS_WYOwAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cSct8bzKD_9D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}